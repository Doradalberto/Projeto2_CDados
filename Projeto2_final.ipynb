{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Isadora Stigliani Dalberto\n",
    "\n",
    "Nome: Matheus Amaral Ricardo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@MatheuseDora1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @MatheuseDora1\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "#produto = 'Era uma vez em Hollywood'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "#n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "#t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "#lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "#i = 1\n",
    "#msgs = []\n",
    "#for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "#    msgs.append(msg.text.lower())\n",
    "#    i += 1\n",
    "#    if i > n:\n",
    "#        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "#shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "#if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "#    #Abre o arquivo para escrita\n",
    "#    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "#    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "#    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "#    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "#    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "#    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abre o arquivo com a coluna \"Relevância\" adicionada manualmente no Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinamento = pd.read_excel('Era uma vez em Hollywood.xlsx', sheet_name=\"Treinamento\")\n",
    "teste = pd.read_excel('Era uma vez em Hollywood.xlsx', sheet_name=\"Teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    import string\n",
    "    punctuation = '[!-.:?;\\s@]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed \n",
    "\n",
    "print() #Espaçamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separação dos tweets entre Relevante (1) e Irrelevante(0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "treinamento_relevancia1 = treinamento.loc[treinamento['Relevancia']==1,:]\n",
    "treinamento_relevancia0 = treinamento.loc[treinamento['Relevancia']==0,:]\n",
    "print() #Espaçamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tranforma todos os caracteres em Minúsculas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "treinamento_string1 = treinamento_relevancia1.Treinamento.str.lower()\n",
    "treinamento_string0 = treinamento_relevancia0.Treinamento.str.lower()\n",
    "print() #Espaçamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpa o Texto (retira caracteres especiais)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "treinamento_clean1=treinamento_string1.apply(cleanup)\n",
    "treinamento_clean0=treinamento_string0.apply(cleanup)\n",
    "print() #Espaçamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tranforma a tabela em um Textão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "treinamento_textao1 = treinamento_clean1.str.cat(sep=' ', na_rep=' ')\n",
    "treinamento_textao0 = treinamento_clean0.str.cat(sep=' ', na_rep=' ')\n",
    "print() #Espaçamento\n",
    "total = treinamento_textao1 + treinamento_textao0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separa as palavras do texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "treinamento_split1 = pd.Series(treinamento_textao1.split())\n",
    "treinamento_split0 = pd.Series(treinamento_textao0.split())\n",
    "serie_total = pd.Series(total.split())\n",
    "print() #Espaçamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value Counts para os Tweets Relevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "treinamento1_contagem = treinamento_split1.value_counts()\n",
    "treinamento1_contagem_relativa = treinamento_split1.value_counts(True)\n",
    "print() #Espaçamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value Counts para os Tweets não Relevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "treinamento0_contagem = treinamento_split0.value_counts()\n",
    "treinamento0_contagem_relativa = treinamento_split0.value_counts(True)\n",
    "print() #Espaçamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P(0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33813353282214326"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_total_absuluta = serie_total.value_counts(False)\n",
    "p0 = treinamento0_contagem.sum()/tabela_total_absuluta.sum()\n",
    "p0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P(1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6618664671778567"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_total_absuluta = serie_total.value_counts(False)\n",
    "p1 = treinamento1_contagem.sum()/tabela_total_absuluta.sum()\n",
    "p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(0|frase) = \\frac{P(frase|0)P(0)}{P(frase)}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "P(1|frase) = \\frac{P(frase|1)P(1)}{P(frase)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transforma todos os caracteres do Teste em Minúscula**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_string = teste.Teste.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpa o Texto (retira caracteres especiais)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_clean = teste_string.apply(cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tranforma a tabela em um Textão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_textao = teste_clean.str.cat(sep=' ', na_rep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separa as palavras do texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_split = pd.Series(teste_textao.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value Counts para os Tweets Relevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_contagem = teste_split.value_counts()\n",
    "teste_contagem_relativa = teste_split.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Código de separação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelv = []\n",
    "irrelf = []\n",
    "relv = []\n",
    "relf = []\n",
    "\n",
    "for frase in teste.loc[teste['Relevancia']==1,:]['Teste']:\n",
    "    pf0 = ((treinamento0_contagem[frase.split()]+1)/len(serie_total)).prod()\n",
    "    p0f = (pf0 * p0) / teste_contagem_relativa[frase.split()].prod()\n",
    "    pf1 = ((treinamento1_contagem[frase.split()]+1)/len(serie_total)).prod()\n",
    "    p1f = (pf1 * p1) / teste_contagem_relativa[frase.split()].prod()\n",
    "    if p1f>p0f:\n",
    "        relv.append(frase)\n",
    "    elif p1f<p0f:\n",
    "        relf.append(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frase in teste.loc[teste['Relevancia']==0,:]['Teste']:\n",
    "    pf0 = ((treinamento0_contagem[frase.split()]+1)/len(serie_total)).prod()\n",
    "    p0f = (pf0 * p0) / teste_contagem_relativa[frase.split()].prod()\n",
    "    pf1 = ((treinamento1_contagem[frase.split()]+1)/len(serie_total)).prod()\n",
    "    p1f = (pf1 * p1) / teste_contagem_relativa[frase.split()].prod()\n",
    "    if p1f>p0f:\n",
    "        irrelf.append(frase)\n",
    "    elif p1f<p0f:\n",
    "        irrelv.append(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros Negativos: 15.5%\n",
      "Falsos Negativos: 37.0%\n",
      "Falsos Positivos: 18.5%\n",
      "Verdadeiros Positivos: 28.999999999999996%\n"
     ]
    }
   ],
   "source": [
    "irrelvporc = len(irrelv)/len(teste)*100\n",
    "print('Verdadeiros Negativos: {0}%'.format(irrelvporc))\n",
    "irrelfporc = len(irrelf)/len(teste)*100\n",
    "print('Falsos Negativos: {0}%'.format(irrelfporc))\n",
    "relfporc = len(relf)/len(teste)*100\n",
    "print('Falsos Positivos: {0}%'.format(relfporc))\n",
    "relvporc = len(relv)/len(teste)*100\n",
    "print('Verdadeiros Positivos: {0}%'.format(relvporc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão:\n",
    "\n",
    "   Neste trabalho realizamos a análise de tweets relacionados ao filme \"Era Uma Vez em Hollywood\", e, através de tweets classificados entre relevantes ou não relevantes, criamos um classificador de novos tweets, que a partir da análise probabilística das palavras contidas naqueles, os classificaria em relevantes ou não relevantes.\n",
    "    \n",
    "   Após a análise das porcentagens de tweets verdadeiros positivos (mensagens relevantes marcadas como relevantes), verdadeiros negativos (mensagens irrelevantes marcadas como irrelevantes), falsos positivos (mensagens irrelevantes marcadas como relevantes) e falsos negativos (mensagens relevantes marcadas como irrelevantes), podemos concluir que nosso classificador nâo foi eficaz, visto que as porcentagens de falsos, somadas, equivalem a 55,5% das mensagens.\n",
    "    \n",
    "   Os verdadeiros positivos são quase o dobro dos verdadeiros negativos e os falsos negativos são a maioria devido às mensagens com dupla negação ou sarcasmo, que acabam sendo classificadas como negativas, já que nosso trabalho basea-se em probabilidade do aparecimento de palavras, logo são tratadas apenas como números, não pelo sentido da frase, o que acaba classificando mensagens que seriam positivas como negativas. Devido aos mesmos fatores que o número de verdadeiros positivos é maior do que falsos positivos, mas o número de falsos negativos é maior do que de verdadeiros negativos.\n",
    "    \n",
    "   Contudo, o financiamento de nosso projeto deve ser alongado pela empresa de modo que possamos chegar a um classificador mais eficiente (que classifique tweets em tempo real e ampliar o número de categorias), visto que sabemos que para melhorá-lo devemos levar em consideração sarcasmo, dupla negação, caracteres acoplados, logo sabemos como alcançá-lo, para que a empresa possa se beneficiar ao obter informações sobre a opinião das pessoas sobre o filme, o tipo de pessoa que gosta deste, como melhorar a partir dos comentários negativos e não perder tempo com mensagens irrelevantes, que atrapalham este processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
